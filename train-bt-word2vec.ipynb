{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "session = boto3.session.Session()\n",
    "aws_region = session.region_name\n",
    "s3_bucket  =  # s3 bucket name\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.get_bucket_location(Bucket=s3_bucket)\n",
    "    print(f\"Bucket region: {response['LocationConstraint']}\")\n",
    "except:\n",
    "    print(f\"Access Error: Check if '{s3_bucket}' S3 bucket is in '{aws_region}' region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = \"models/word2vec/dbpedia/v1\"\n",
    "s3_output_location = f\"s3://{s3_bucket}/{s3_prefix}\"\n",
    "print(f\"Model output location:{s3_output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"blazingtext\", aws_region, \"1\")\n",
    "print(f\"Using SageMaker BlazingText container: {container} ({aws_region})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "bt_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.4xlarge\",\n",
    "    volume_size=100,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.set_hyperparameters(\n",
    "    mode=\"skipgram\",\n",
    "    epochs=20,\n",
    "    min_count=5,\n",
    "    sampling_threshold=0.0001,\n",
    "    learning_rate=0.05,\n",
    "    window_size=5,\n",
    "    vector_dim=150,\n",
    "    negative_samples=5,\n",
    "    evaluation=True,  # Perform similarity evaluation on WS-353 dataset at the end of training\n",
    "    subwords=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "s3_train = f\"s3://{s3_bucket}/blazing-text/word2vec/dbpedia\"\n",
    "\n",
    "train_input = TrainingInput(s3_data=s3_train, \n",
    "                            distribution=\"FullyReplicated\", \n",
    "                            s3_data_type=\"S3Prefix\", \n",
    "                            input_mode=\"File\")\n",
    "\n",
    "data_channels = {\"train\": train_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=\"All\", wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint = bt_model.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "words = [\"extraordinary\", \"amazing\"]\n",
    "\n",
    "payload = {\"instances\": words}\n",
    "\n",
    "response = bt_endpoint.predict(\n",
    "    json.dumps(payload),\n",
    "    initial_args={\"ContentType\": \"application/json\", \"Accept\": \"application/json\"},\n",
    ")\n",
    "\n",
    "vecs = json.loads(response)\n",
    "print(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "key = bt_model.model_data[bt_model.model_data.find(\"/\", 5) + 1 :]\n",
    "s3.Bucket(s3_bucket).download_file(key, \"model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat eval.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Read the 400 most frequent word vectors. The vectors in the file are in descending order of frequency.\n",
    "num_points = 400\n",
    "\n",
    "first_line = True\n",
    "index_to_word = []\n",
    "with open(\"vectors.txt\", \"r\") as f:\n",
    "    for line_num, line in enumerate(f):\n",
    "        if first_line:\n",
    "            dim = int(line.strip().split()[1])\n",
    "            word_vecs = np.zeros((num_points, dim), dtype=float)\n",
    "            first_line = False\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        word = line.split()[0]\n",
    "        vec = word_vecs[line_num - 1]\n",
    "        for index, vec_val in enumerate(line.split()[1:]):\n",
    "            vec[index] = float(vec_val)\n",
    "        index_to_word.append(word)\n",
    "        if line_num >= num_points:\n",
    "            break\n",
    "word_vecs = normalize(word_vecs, copy=False, return_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=40, n_components=2, init=\"pca\", n_iter=10000)\n",
    "two_d_embeddings = tsne.fit_transform(word_vecs[:num_points])\n",
    "labels = index_to_word[:num_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot(embeddings, labels):\n",
    "    pylab.figure(figsize=(20, 20))\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i, :]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(\n",
    "            label, xy=(x, y), xytext=(5, 2), textcoords=\"offset points\", ha=\"right\", va=\"bottom\"\n",
    "        )\n",
    "    pylab.show()\n",
    "\n",
    "\n",
    "plot(two_d_embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint.delete_endpoint(delete_endpoint_config=True)\n",
    "bt_endpoint.delete_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-destruction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
